{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scikitplot as skplt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import metrics\n",
    "\n",
    "# Keras\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.estimator import DNNClassifier\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer, one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Dropout, Embedding, Flatten, Conv1D, MaxPooling1D, LSTM\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@Starrbby too bad I won't be around I lost my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>amazon s3 plugin not worked in my website . it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>The Hoyts Distribution NZ website isn't workin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>dang won't be able to get to any workshops run...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Tried to install a Twitter-application on my p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text\n",
       "0       0  @Starrbby too bad I won't be around I lost my ...\n",
       "1       0  amazon s3 plugin not worked in my website . it...\n",
       "2       0  The Hoyts Distribution NZ website isn't workin...\n",
       "3       0  dang won't be able to get to any workshops run...\n",
       "4       0  Tried to install a Twitter-application on my p..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/mixed_data_1200.csv\", sep=';')\n",
    "df = df.drop([\"Unnamed: 0\"],axis=1)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converts whitespaces\n",
    "trb_nan_idx = df[pd.isnull(df['text'])].index.tolist()\n",
    "df.loc[trb_nan_idx, 'text'] = ' '\n",
    "X_load = df[\"text\"]\n",
    "Y_load = df[\"target\"]\n",
    "\n",
    "#Creation of a dictionary with #0 = negative to 0, 2 = neutral to 1, 4 = positive to 2\n",
    "dicc = {0:0,2:1,4:2}\n",
    "Y_load = Y_load.map(dicc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Data to fit for softmax activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_traink ,X_testk, y_traink, y_testk = train_test_split(X_load,Y_load,test_size=0.2,random_state=42,shuffle=True)\n",
    "y_test = y_testk\n",
    "\n",
    "tokenizer = Tokenizer(lower=True,filters = \"!\\\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\", split = \" \")\n",
    "tokenizer.fit_on_texts(X_traink)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Data to fit for softmax activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer encode documents // standard bag-of-words of length vocab size => len(t.word_index) = 7282\n",
    "encoded_tweets = tokenizer.texts_to_matrix(X_load, mode='tfidf') #binary / count / tfidf / freq\n",
    "X_traink = tokenizer.texts_to_matrix(X_traink, mode='tfidf') #binary / count / tfidf / freq\n",
    "X_testk = tokenizer.texts_to_matrix(X_testk, mode='tfidf') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary includes 6386 unique words and 3310 tweets\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(encoded_tweets[0])\n",
    "tweets_size = len(encoded_tweets)\n",
    "print('The vocabulary includes {} unique words and {} tweets'.format(vocab_size,tweets_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Data to fit for softmax activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "num_classes = max(y_traink+1)\n",
    "print(num_classes)\n",
    "y_traink = tf.keras.utils.to_categorical(y_traink,num_classes=3)\n",
    "y_testk = tf.keras.utils.to_categorical(y_testk,num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " ...\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_traink)\n",
    "print(y_testk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 6465\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128,input_shape=(6465, )))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "epochs = 5\n",
    "\n",
    "history = model.fit(X_traink,y_traink,batch_size=batch_size,epochs=epochs,verbose=1,validation_split=0.1)\n",
    "scores = model.evaluate(X_testk,y_testk,batch_size=batch_size,verbose=1)\n",
    "\n",
    "print(\"Accuracy is: {}\".format(scores[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF encoded Matrix of tweets\n",
    "#dfidf_df = pd.DataFrame(data=encoded_tweets)\n",
    "#dfidf_df\n",
    "#dflatex1 = dfidf_df.iloc[[0,1,2,3,-3,-2,-1], [0,1,2,3,-3,-2,-1]]\n",
    "#print(dflatex1.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(X_testk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxx = [\"Today my PC crashed what a shit I can not work I am so stressed\"]\n",
    "xxx1 =  tokenizer.texts_to_matrix(xxx)\n",
    "#xxx2 = pad_sequences(xxx1,maxlen=max_sequence_length,padding=\"post\", truncating='post',dtype='int32',value=0.)\n",
    "pred = model.predict_classes(xxx1)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, predictions,target_names=[\"techno-stress\",\"neutral\",\"positive\"]))\n",
    "report = metrics.classification_report(y_test, predictions,target_names=[\"techno-stress\",\"neutral\",\"positive\"],output_dict=True)\n",
    "reportdf = pd.DataFrame(report).transpose()\n",
    "#print(reportdf.to_latex())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "skplt.metrics.plot_confusion_matrix(y_test,predictions,normalize=False)\n",
    "plt.title(\"Confusion Matrix Simple DNN\")\n",
    "#cnf_matrix = metrics.confusion_matrix(y_test, predictions)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "ipykernel_py3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
